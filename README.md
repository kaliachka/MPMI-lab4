Лабораторная работа 4
===
Использование техник аугментации данных для улучшения сходимости процесса обучения нейронной сети на примере решения задачи классификации Oregon Wildlife
---
### 1. С использованием, техники обучения Transfer Learning и оптимальной политики изменения темпа обучения обучить нейронную сеть EfficientNet-B0 (предварительно обученную на базе изображений imagenet) для решения задачи классификации изображений Oregon WildLife с использованием следующих техник аугментации данных:

#### Аугментация данных (англ. data augmentation) — это методика создания дополнительных данных из имеющихся данных.

### 1.1. Манипуляции с яркостью и контрастом:
##### В первом пункт мы использовали технику аугментации изображений путем манипуляции с яркостью и контрастом. Для реализации данного способа были написаны функции:
```
def contrast(image, label):
    return tf.image.adjust_contrast(image, 0.4), label

def brightness(image, label):
    return tf.image.adjust_brightness(image, delta=0.1), label
```
#####  Функция contrast возвращает tf.image.adjust_contrast(image, contrast_factor), где параметр image - входное изображение и contrast_factor - множитель типа float для регулировки контраста. Функция brightness возвращает tf.image.adjust_brightness(image, delta), где параметр image - входное изображение и delta - скалярная величина, добавляемая к значениям пикселей.

##### Функция вызывается в TFRecordDataset:

```
return tf.data.TFRecordDataset(filenames)\
    .map(contrast)\
    .map(brightness)\
```
##### Для нахождения оптимальных значений мною были выбраны следующие параметры:

* contrast_factor = 0.4, delta = 0.1;
* contrast_factor = 0.5, delta = 0.05;
* contrast_factor = 0.5, delta = 0.1;
* contrast_factor = 0.5, delta = 0.2;
* contrast_factor = 1, delta = 1;
* contrast_factor = 3, delta = 0.5;
* contrast_factor = 5, delta = 0.1;

**График метрики точности:**

![2](https://user-images.githubusercontent.com/59210216/112891910-5ac78a80-90e1-11eb-8d88-f346bc7d0fe8.jpg)

![1](https://user-images.githubusercontent.com/59210216/112891891-569b6d00-90e1-11eb-8e33-98bc49e92090.jpg)

**График функции потерь:**

![4](https://user-images.githubusercontent.com/59210216/112891925-61560200-90e1-11eb-8cdc-35633ac32de9.jpg)

![3](https://user-images.githubusercontent.com/59210216/112891917-5e5b1180-90e1-11eb-98ce-dcc23772a265.jpg)

#### Анализ полученных результатов:

В данной части лабораторной работы использовались параметры contrast_factor и delta с изменяемыми значениями. Анализируя полученные диаграммы можно сделать вывод, что наилучшим по показателям оказался случай с параметрами contrast_factor = 1, delta = 1 (серая ломаная); При описанных выше параметрах достигается максимальное значение метрики качества на валидации, равное 88.86%, потери при этом составили 0.2581. Это значение мы и примем за оптимальное для данного случая.

### 1.2.1. Поворот изображения на случайный угол:
##### В данном пункте мы использовали технику аугментации изображений путем поворота изображения на случайный угол. Для реализации данного способа были написаны функции:

```
x = tf.keras.layers.experimental.preprocessing.RandomRotation(factor=(-0.025, 0.025))(inputs)
```
##### По умолчанию случайное вращение применяется только во время тренировки. Во время вывода слой ничего не делает. Random Rotation используется с помощью препроцессинга, основной задачей которого является отображение данных в формат пригодный для обучения модели.

##### В Random Rotation используется такой параметр, как factor - величина, представленная как часть 2pi, представляющая нижнюю и верхнюю границу для вращения по и против часовой стрелки. Положительные значения означают вращение против часовой стрелки, а отрицательные - по часовой стрелке. При представлении в виде одного числа с плавающей запятой это значение используется как для верхней, так и для нижней границы.

##### Для нахождения оптимальных значений мною были выбраны следующие параметры:

* factor = (-0.025, 0.025); /*диапазон от -9 до 9 градусов*/
* factor = (0.25, 0.5); /*диапазон от 90 до 180 градусов*/
* factor = (0.25); /*диапазон от -90 до 90 градусов*/
* factor = (0, 0.75); /*диапазон от 0 до 270 градусов*/
* factor = (0, 0.025); /*диапазон от 0 до 9 градусов*/

**График метрики точности:**

![2](https://user-images.githubusercontent.com/59210216/112891958-6c109700-90e1-11eb-95cb-fb90d71b4952.jpg)

![1](https://user-images.githubusercontent.com/59210216/112891940-67e47980-90e1-11eb-833b-698282ae106b.jpg)

**График функции потерь:**

![4](https://user-images.githubusercontent.com/59210216/112891983-729f0e80-90e1-11eb-9cbc-5528a712b34a.jpg)

![3](https://user-images.githubusercontent.com/59210216/112891971-6f0b8780-90e1-11eb-9a98-ecb10def79d8.jpg)

#### Анализ полученных результатов:

В данной части лабораторной работы использовался параметр factor с изменяемыми значениями. Анализируя полученные диаграммы можно сделать вывод, что наилучшим по показателям оказался случай с параметром factor = (0, 0.025), синяя ломаная; При описанных выше параметрах достигается максимальное значение метрики качества на валидации, равное 88.16%, потери при этом составили 0.2831.

### 1.2.2. Поворот изображения на случайный угол с использованием параметра режим заполнения fill_mode:

##### Хочется отметить, что наравне с параметром factor, также имеют место и другие параметры, такие как fill_mode, interpolation, seed и т.д. Используя полученное оптимальное значение factor, в данном пункте был также использован параметр fill_mode (точки за пределами ввода). Данные точки заполняются в соответствии с одним из заданных режимов: 

* 'constant' - входные данные расширяются путем заполнения всех значений за пределами края одним и тем же постоянным значением k = 0;
* 'reflect' - входные данные расширяются за счет отражения около края последнего пикселя;
* 'wrap' - входные данные расширяются за счет перехода к противоположному краю;
* 'nearest' - входные данные расширяются до ближайшего пикселя.

**График метрики точности:**

![2](https://user-images.githubusercontent.com/59210216/112892025-7fbbfd80-90e1-11eb-964b-a1802b1a1794.jpg)

![1](https://user-images.githubusercontent.com/59210216/112892004-792d8600-90e1-11eb-8478-94fb9a0e0294.jpg)

**График функции потерь:**

![4](https://user-images.githubusercontent.com/59210216/112892056-877ba200-90e1-11eb-894b-d37c7644c413.jpg)

![3](https://user-images.githubusercontent.com/59210216/112892050-8480b180-90e1-11eb-982a-e0acc17f6bf9.jpg)

#### Анализ полученных результатов:

В данной части лабораторной работы использовался параметр fill_mode с изменяемыми режимами. Анализируя полученные диаграммы можно заметить, что при использовании режима 'nearest' достигается максимальное значение метрики качества на валидации равное 88.47%, однако потери при этом составили 0.2847 и сошелся на 25 эпохе. В то время как при использовании параметра 'wrap', потери составили 0.2832 и сошелся на 19 эпохе, а значение метрики качества на валидации равняется 88.03%, что немногим меньше максимального значения. Наилучшим по показателям оказался случай с режимом 'wrap', голубая ломаная.

Анализируя данные, полученные при использовании техники поворота изображения на случайный угол и техники поворота изображения на случайный угол с использованием параметра режим заполнения fill_mode, и сравнив полученные результаты, можно сделать вывод, что оптимальным значением из этих двух случаев будет техники поворота изображения на случайный угол  с параметром factor = (0, 0.025): максимальное значение метрики качества на валидации состовляет 88.16%, что на 0.13% выше техники поворота изображения на случайный угол с использованием параметра режим заполнения fill_mode.

### 1.3. Добавление случайного шума:

##### Для реализации данного способа был добавлен слой:
```
x = tf.keras.layers.GaussianNoise(0.01)(inputs)
```
или в общем виде:
```
tf.keras.layers.GaussianNoise(stddev), где stddev - среднеквадратичного отклонения добавляемого шума.
```
##### Для нахождения оптимальных значений мною были выбраны следующие параметры:

* stddev = 0.01; 
* stddev = 0.05;
* stddev = 0.1; 
* stddev = 0.5; 
* stddev = 1;

**График метрики точности:**

![2](https://user-images.githubusercontent.com/59210216/112892099-95312780-90e1-11eb-8057-060d4a0c3f12.jpg)

![1](https://user-images.githubusercontent.com/59210216/112892077-8e0a1980-90e1-11eb-8d4f-a022a2c38c92.jpg)

**График функции потерь:**

![4](https://user-images.githubusercontent.com/59210216/112892122-9bbf9f00-90e1-11eb-8ed6-e0719ca91765.jpg)

![3](https://user-images.githubusercontent.com/59210216/112892113-98c4ae80-90e1-11eb-82c5-4267994b0dde.jpg)

#### Анализ полученных результатов:

В данной части лабораторной работы использовался параметр stddev с изменяемыми значениями. Анализируя полученные диаграммы можно сделать вывод, что наилучшим по показателям оказался случай с параметром stddev = 0.01, синяя ломаная; При описанных выше параметрах достигается максимальное значение метрики качества на валидации, равное 89.04%, потери при этом составили 0.2615. Это значение мы и примем за оптимальное для данного случая.

### 1.4. Использование случайной части изображения:

##### В данном пункте мы использовали технику аугментации изображений путем использования случайной части изображения. Для реализации данного способа были добавлены слои:

```
x = tf.keras.layers.experimental.preprocessing.Resizing(250,250)(inputs)
x = tf.keras.layers.experimental.preprocessing.RandomCrop(224,224)(x)
```
или в общем виде:
```
tf.keras.layers.experimental.preprocessing.RandomCrop(height, width), где height и width - высота и ширина соответсвенно.
```
##### Для нахождения оптимальных значений мною были выбраны следующие параметры:

* RandomCrop(100,100), Resizing(224,224);
* RandomCrop(112,112), Resizing(224,224);
* RandomCrop(150,150), Resizing(224,224);
* RandomCrop(200,200), Resizing(224,224);

**График метрики точности:**

![2](https://user-images.githubusercontent.com/59210216/112892160-a712ca80-90e1-11eb-8b7d-315c8e87a5d8.jpg)

![1](https://user-images.githubusercontent.com/59210216/112892150-a417da00-90e1-11eb-900f-1d0dbc14ca78.jpg)

**График функции потерь:**

![4](https://user-images.githubusercontent.com/59210216/112892177-ab3ee800-90e1-11eb-88f6-ce7421ae168b.jpg)

![3](https://user-images.githubusercontent.com/59210216/112892166-a9752480-90e1-11eb-98c1-fe7b07921e05.jpg)

#### Анализ полученных результатов:

В данной части лабораторной работы использовались параметры RandomCrop и Resizing с изменяемыми значениями. Анализируя полученные диаграммы можно сделать вывод, что наилучшим по показателям оказался случай с параметрами RandomCrop(200,200) и Resizing(224,224) (оранжевая ломаная); При описанных выше параметрах достигается максимальное значение метрики качества на валидации, равное 87.12%, потери при этом составили 0.312. Это значение мы и примем за оптимальное для данного случая.

### 2. Для каждой индивидуальной техники аугментации определить оптимальный набор параметров:

Чтобы понять, что работа выполнена верно, был проведен сравнительный анализ оптимальных значений каждого из пунктов и политики пошагового затухания (Step Decay) из предыдущей лабораторной работы:

**График метрики точности:**

![1](https://user-images.githubusercontent.com/59210216/112917330-15b84e00-910b-11eb-8356-be56e4ca3f4d.jpg)

![2](https://user-images.githubusercontent.com/59210216/112917343-19e46b80-910b-11eb-9917-83ce9b16ec42.jpg)

**График функции потерь:**

![3](https://user-images.githubusercontent.com/59210216/112917352-1e108900-910b-11eb-91cf-c33add0c6bfb.jpg)

![4](https://user-images.githubusercontent.com/59210216/112917362-236dd380-910b-11eb-9e11-6d777e2079e3.jpg)

#### Анализ полученных результатов:
* Анализируя полученные результаты, хочется отметить, что при использовании техники манипуляции с яркостью и контрастом было получено значение метрики качества на валидации, равное 88.86%, что почти на 1% ниже, чем оптимальное значение для политики пошагового затухания. Однако при использовании техники манипуляции с яркостью и контрастом, график оптимального значения сошелся на 21й эпохе, в то время как оптимальный график для политики пошагового затухания не сошелся вовсе. Значение потерь при использовании техники манипуляции с яркостью и контрастом равняется 0.2581, что на 0.1313 ниже значения для политики пошагового затухания.
* Если говорить о технике поворота изображения на случайный угол, то мною было получено значение метрики качества на валидации, равное 88.16%, что на 1.64% ниже, чем оптимальное значение для политики пошагового затухания. Однако при использовании техники манипуляции с яркостью и контрастом, график оптимального значения сошелся на 24й эпохе, в то время как оптимальный график для политики пошагового затухания не сошелся вовсе. Значение потерь при использовании техники поворота изображения на случайный угол равняется 0.2831, что на 0.1063 ниже значения для политики пошагового затухания.
* При использовании техники добавления случайного шума значение метрики качества на валидации равно 89.04%, что на 0.76% ниже, чем оптимальное значение для политики пошагового затухания. Однако при использовании техники манипуляции с яркостью и контрастом, график оптимального значения сошелся к 28й эпохе, в то время как оптимальный график для политики пошагового затухания не сошелся вовсе. Значение потерь при использовании техники добавления случайного шума равняется 0.2615, что на 0.1279 ниже значения для политики пошагового затухания.
* Если говорить о технике использования случайной части изображения, значение метрики качества на валидации равно 87.12%, что на 2.68% ниже, чем оптимальное значение для политики пошагового затухания. Однако при использовании техники манипуляции с яркостью и контрастом, график оптимального значения сошелся к 28й эпохе, в то время как оптимальный график для политики пошагового затухания не сошелся вовсе. Значение потерь при использовании техники использования случайной части изображения равняется 0.312, что на 0.0774 ниже значения для политики пошагового затухания.
Таким образом все изложенные выше факторы говорят об улучшении сходимости алгоритма обучения.

### 3. Обучить нейронную сеть с использованием оптимальных техник аугментации данных 2a-d совместно:

В данной части лабораторной работы необходимо было обучить нейронную сеть с использованием оптимальных техник аугментации данных совместно. Если говорить подробнее, то были использованы техники:
* Манипуляции с яркостью и контрастом со значениями contrast_factor = 1, delta = 1;
* Поворота изображения на случайный угол с параметром factor = (0, 0.025);
* Добавления случайного шума с параметром stddev = 0.01;
* Использования случайной части изображения с параметрами RandomCrop(200,200) и Resizing(224,224).
    
**График метрики точности:**

![1-1](https://user-images.githubusercontent.com/59210216/112919007-db50b000-910e-11eb-8f69-e726fd9d3fd9.jpg)

![2-1](https://user-images.githubusercontent.com/59210216/112919036-e572ae80-910e-11eb-9214-f24de73845ea.jpg)

**График функции потерь:**

![3-1](https://user-images.githubusercontent.com/59210216/112919044-e99ecc00-910e-11eb-8838-9466214a336f.jpg)

![4-1](https://user-images.githubusercontent.com/59210216/112919052-eefc1680-910e-11eb-92a5-785258bedd1f.jpg)

#### Анализ полученных результатов:
Анализируя приведенные выше графики можно отметить, что совместное применение техник аугментации данных с оптимальными для каждого из случаев значениями весьма положительно влияет на обучение нейронной сети, ведь:

1. Скорость схождения алгоритма с аугментацией увеличась на 21 эпоху, по сравнению политикой без аугментации;
2. Значение потерь уменьшилось на 0.0366;

Однако присутствуют и отрицательные аспекты, которые не позволяют назвать данный метод идеальным:

1. Значение метрики качества на валидации уменьшилось на 2.5%;
Тем не менее, основываясь на всех предыдущих высказываниях можно сделать вывод, что совместное использование техник аугментации данных приводит к улучшению сходимости алгоритма обучения.
